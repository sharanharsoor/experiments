{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sharanharsoor/fine-tuning-gpt-2-on-bhagavad-gita-dataset?scriptVersionId=196482114\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"9cf413d5","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-13T08:36:40.003005Z","iopub.status.busy":"2024-09-13T08:36:40.001865Z","iopub.status.idle":"2024-09-13T08:36:41.343647Z","shell.execute_reply":"2024-09-13T08:36:41.342567Z","shell.execute_reply.started":"2024-09-13T08:36:40.002956Z"},"papermill":{"duration":0.006843,"end_time":"2024-09-13T09:35:42.308759","exception":false,"start_time":"2024-09-13T09:35:42.301916","status":"completed"},"tags":[]},"source":["# Introduction.\n","In this notebook, I am fine-tuning a GPT-2 model on a Bhagavad Gita dataset to generate responses related to various verses. The process involves loading and tokenizing the dataset, converting the text into a format suitable for GPT-2, and then training the model with a focus on both English and Sanskrit translations. The fine-tuned model is later evaluated by generating responses to predefined queries about the Bhagavad Gita. The implementation includes steps for data processing, model training, evaluation, and ensuring memory efficiency with strategies like gradient accumulation and mixed precision. Finally, I evaluate the model by generating answers to specific Bhagavad Gita-related questions."]},{"cell_type":"markdown","id":"c5cca6a0","metadata":{"papermill":{"duration":0.005254,"end_time":"2024-09-13T09:35:42.319717","exception":false,"start_time":"2024-09-13T09:35:42.314463","status":"completed"},"tags":[]},"source":["## Overview of the Process:\n","\n","1. **Loading and Processing Data:**\n","   - Load the Bhagavad Gita dataset from a CSV file.\n","   - The dataset includes Shlokas (Sanskrit verses), transliterations, and translations in English and Hindi.\n","   - Data is preprocessed and displayed to ensure correctness before further steps.\n","\n","2. **Tokenization:**\n","   - Use the GPT-2 tokenizer to encode the text data.\n","   - The `pad_token` is set to the `eos_token` because GPT-2 doesn’t have a padding token by default.\n","   - Tokenization is done for both prompts (Sanskrit verses) and responses (translations).\n","\n","3. **Preparing Data for Model Training:**\n","   - Convert the dataset into a format compatible with the Hugging Face library.\n","   - The dataset is tokenized with truncation and padding, and labels are prepared by masking padding tokens.\n","   - This step ensures the model understands both inputs (verses) and outputs (translations).\n","\n","4. **Training the GPT-2 Model:**\n","   - Split the dataset into training and validation sets.\n","   - Define training arguments with memory optimization techniques like gradient accumulation and mixed precision (FP16).\n","   - Log the training process using a custom callback to track loss and monitor model performance.\n","\n","5. **Evaluation and Model Generation:**\n","   - After training, the model is evaluated using predefined queries from the Bhagavad Gita.\n","   - The fine-tuned model generates answers to these queries, leveraging both English translations and Sanskrit verses.\n","\n","6. **Saving and Using the Model:**\n","   - The trained model and tokenizer are saved for future use.\n","   - Evaluate the model by generating responses to Bhagavad Gita-related questions, demonstrating the ability of the fine-tuned model to generate relevant answers.\n"]},{"cell_type":"markdown","id":"8b188f9b","metadata":{"papermill":{"duration":0.005201,"end_time":"2024-09-13T09:35:42.330829","exception":false,"start_time":"2024-09-13T09:35:42.325628","status":"completed"},"tags":[]},"source":["## Loading of dataset"]},{"cell_type":"code","execution_count":1,"id":"4d6027c3","metadata":{"execution":{"iopub.execute_input":"2024-09-13T09:35:42.343469Z","iopub.status.busy":"2024-09-13T09:35:42.342936Z","iopub.status.idle":"2024-09-13T09:35:43.815464Z","shell.execute_reply":"2024-09-13T09:35:43.814451Z"},"papermill":{"duration":1.481919,"end_time":"2024-09-13T09:35:43.818151","exception":false,"start_time":"2024-09-13T09:35:42.336232","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Chapter</th>\n","      <th>Verse</th>\n","      <th>Shloka</th>\n","      <th>Transliteration</th>\n","      <th>HinMeaning</th>\n","      <th>EngMeaning</th>\n","      <th>WordMeaning</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>BG1.1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>धृतराष्ट्र उवाच |\\nधर्मक्षेत्रे कुरुक्षेत्रे स...</td>\n","      <td>dhṛtarāṣṭra uvāca .\\ndharmakṣetre kurukṣetre s...</td>\n","      <td>।।1.1।।धृतराष्ट्र ने कहा -- हे संजय ! धर्मभूमि...</td>\n","      <td>1.1 Dhritarashtra said  What did my people and...</td>\n","      <td>1.1 धर्मक्षेत्रे on the holy plain? कुरुक्षेत्...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>BG1.2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>सञ्जय उवाच |\\nदृष्ट्वा तु पाण्डवानीकं व्यूढं द...</td>\n","      <td>sañjaya uvāca .\\ndṛṣṭvā tu pāṇḍavānīkaṃ vyūḍha...</td>\n","      <td>।।1.2।।संजय ने कहा -- पाण्डव-सैन्य की व्यूह रच...</td>\n","      <td>1.2. Sanjaya said  Having seen the army of the...</td>\n","      <td>1.2 दृष्ट्वा having seen? तु indeed? पाण्डवानी...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>BG1.3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>पश्यैतां पाण्डुपुत्राणामाचार्य महतीं चमूम् |\\n...</td>\n","      <td>paśyaitāṃ pāṇḍuputrāṇāmācārya mahatīṃ camūm .\\...</td>\n","      <td>।।1.3।।हे आचार्य ! आपके बुद्धिमान शिष्य द्रुपद...</td>\n","      <td>1.3. \"Behold, O Teacher! this mighty army of t...</td>\n","      <td>1.3 पश्य behold? एताम् this? पाण्डुपुत्राणाम् ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>BG1.4</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>अत्र शूरा महेष्वासा भीमार्जुनसमा युधि |\\nयुयुध...</td>\n","      <td>atra śūrā maheṣvāsā bhīmārjunasamā yudhi .\\nyu...</td>\n","      <td>।।1.4।।इस सेना में महान् धनुर्धारी शूर योद्धा ...</td>\n","      <td>1.4. Here are heroes, mighty archers, eal in b...</td>\n","      <td>1.4 अत्र here? शूराः heroes? महेष्वासाः mighty...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>BG1.5</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>धृष्टकेतुश्चेकितानः काशिराजश्च वीर्यवान् |\\nपु...</td>\n","      <td>dhṛṣṭaketuścekitānaḥ kāśirājaśca vīryavān .\\np...</td>\n","      <td>।।1.5।।धृष्टकेतु, चेकितान, बलवान काशिराज,  पुर...</td>\n","      <td>1.5. \"Dhrishtaketu, chekitana and the valiant ...</td>\n","      <td>1.5 धृष्टकेतुः Dhrishtaketu? चेकितानः Chekitan...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>696</th>\n","      <td>BG18.74</td>\n","      <td>18</td>\n","      <td>74</td>\n","      <td>सञ्जय उवाच |\\nइत्यहं वासुदेवस्य पार्थस्य च महा...</td>\n","      <td>sañjaya uvāca .\\nityahaṃ vāsudevasya pārthasya...</td>\n","      <td>।।18.74।। संजय ने कहा -- इस प्रकार मैंने भगवान...</td>\n","      <td>18.74 Sanjaya said  Thus I have heard this won...</td>\n","      <td>18.74 इति thus? अहम् I? वासुदेवस्य of Krishna?...</td>\n","    </tr>\n","    <tr>\n","      <th>697</th>\n","      <td>BG18.75</td>\n","      <td>18</td>\n","      <td>75</td>\n","      <td>व्यासप्रसादाच्छ्रुतवानेतद्गुह्यमहं परम् |\\nयोग...</td>\n","      <td>vyāsaprasādācchrutavānetadguhyamahaṃ param .\\n...</td>\n","      <td>।।18.75।। व्यास जी की कृपा से मैंने इस परम् गु...</td>\n","      <td>18.75 Through the grace of Vyasa I have heard ...</td>\n","      <td>18.75 व्यासप्रसादात् through the grace of Vyas...</td>\n","    </tr>\n","    <tr>\n","      <th>698</th>\n","      <td>BG18.76</td>\n","      <td>18</td>\n","      <td>76</td>\n","      <td>राजन्संस्मृत्य संस्मृत्य संवादमिममद्भुतम् |\\nक...</td>\n","      <td>rājansaṃsmṛtya saṃsmṛtya saṃvādamimamadbhutam ...</td>\n","      <td>।।18.76।। हे राजन् ! भगवान् केशव और अर्जुन के ...</td>\n","      <td>18.76 O King, remembering this wonderful and h...</td>\n","      <td>18.76 राजन् O King? संस्मृत्य having remembere...</td>\n","    </tr>\n","    <tr>\n","      <th>699</th>\n","      <td>BG18.77</td>\n","      <td>18</td>\n","      <td>77</td>\n","      <td>तच्च संस्मृत्य संस्मृत्य रूपमत्यद्भुतं हरेः |\\...</td>\n","      <td>tacca saṃsmṛtya saṃsmṛtya rūpamatyadbhutaṃ har...</td>\n","      <td>।।18.77।। हे राजन ! श्री हरि के अति अद्भुत रूप...</td>\n","      <td>18.77 And, remembering again and again, also t...</td>\n","      <td>18.77 तत् that? च and? संस्मृत्य having rememb...</td>\n","    </tr>\n","    <tr>\n","      <th>700</th>\n","      <td>BG18.78</td>\n","      <td>18</td>\n","      <td>78</td>\n","      <td>यत्र योगेश्वरः कृष्णो यत्र पार्थो धनुर्धरः |\\n...</td>\n","      <td>yatra yogeśvaraḥ kṛṣṇo yatra pārtho dhanurdhar...</td>\n","      <td>।।18.78।। जहाँ योगेश्वर श्रीकृष्ण हैं और जहाँ ...</td>\n","      <td>18.78 Wherever is Krishna, the Lord of Yoga; w...</td>\n","      <td>18.78 यत्र wherever? योगेश्वरः the Lord of Yog...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>701 rows × 8 columns</p>\n","</div>"],"text/plain":["          ID  Chapter  Verse  \\\n","0      BG1.1        1      1   \n","1      BG1.2        1      2   \n","2      BG1.3        1      3   \n","3      BG1.4        1      4   \n","4      BG1.5        1      5   \n","..       ...      ...    ...   \n","696  BG18.74       18     74   \n","697  BG18.75       18     75   \n","698  BG18.76       18     76   \n","699  BG18.77       18     77   \n","700  BG18.78       18     78   \n","\n","                                                Shloka  \\\n","0    धृतराष्ट्र उवाच |\\nधर्मक्षेत्रे कुरुक्षेत्रे स...   \n","1    सञ्जय उवाच |\\nदृष्ट्वा तु पाण्डवानीकं व्यूढं द...   \n","2    पश्यैतां पाण्डुपुत्राणामाचार्य महतीं चमूम् |\\n...   \n","3    अत्र शूरा महेष्वासा भीमार्जुनसमा युधि |\\nयुयुध...   \n","4    धृष्टकेतुश्चेकितानः काशिराजश्च वीर्यवान् |\\nपु...   \n","..                                                 ...   \n","696  सञ्जय उवाच |\\nइत्यहं वासुदेवस्य पार्थस्य च महा...   \n","697  व्यासप्रसादाच्छ्रुतवानेतद्गुह्यमहं परम् |\\nयोग...   \n","698  राजन्संस्मृत्य संस्मृत्य संवादमिममद्भुतम् |\\nक...   \n","699  तच्च संस्मृत्य संस्मृत्य रूपमत्यद्भुतं हरेः |\\...   \n","700  यत्र योगेश्वरः कृष्णो यत्र पार्थो धनुर्धरः |\\n...   \n","\n","                                       Transliteration  \\\n","0    dhṛtarāṣṭra uvāca .\\ndharmakṣetre kurukṣetre s...   \n","1    sañjaya uvāca .\\ndṛṣṭvā tu pāṇḍavānīkaṃ vyūḍha...   \n","2    paśyaitāṃ pāṇḍuputrāṇāmācārya mahatīṃ camūm .\\...   \n","3    atra śūrā maheṣvāsā bhīmārjunasamā yudhi .\\nyu...   \n","4    dhṛṣṭaketuścekitānaḥ kāśirājaśca vīryavān .\\np...   \n","..                                                 ...   \n","696  sañjaya uvāca .\\nityahaṃ vāsudevasya pārthasya...   \n","697  vyāsaprasādācchrutavānetadguhyamahaṃ param .\\n...   \n","698  rājansaṃsmṛtya saṃsmṛtya saṃvādamimamadbhutam ...   \n","699  tacca saṃsmṛtya saṃsmṛtya rūpamatyadbhutaṃ har...   \n","700  yatra yogeśvaraḥ kṛṣṇo yatra pārtho dhanurdhar...   \n","\n","                                            HinMeaning  \\\n","0    ।।1.1।।धृतराष्ट्र ने कहा -- हे संजय ! धर्मभूमि...   \n","1    ।।1.2।।संजय ने कहा -- पाण्डव-सैन्य की व्यूह रच...   \n","2    ।।1.3।।हे आचार्य ! आपके बुद्धिमान शिष्य द्रुपद...   \n","3    ।।1.4।।इस सेना में महान् धनुर्धारी शूर योद्धा ...   \n","4    ।।1.5।।धृष्टकेतु, चेकितान, बलवान काशिराज,  पुर...   \n","..                                                 ...   \n","696  ।।18.74।। संजय ने कहा -- इस प्रकार मैंने भगवान...   \n","697  ।।18.75।। व्यास जी की कृपा से मैंने इस परम् गु...   \n","698  ।।18.76।। हे राजन् ! भगवान् केशव और अर्जुन के ...   \n","699  ।।18.77।। हे राजन ! श्री हरि के अति अद्भुत रूप...   \n","700  ।।18.78।। जहाँ योगेश्वर श्रीकृष्ण हैं और जहाँ ...   \n","\n","                                            EngMeaning  \\\n","0    1.1 Dhritarashtra said  What did my people and...   \n","1    1.2. Sanjaya said  Having seen the army of the...   \n","2    1.3. \"Behold, O Teacher! this mighty army of t...   \n","3    1.4. Here are heroes, mighty archers, eal in b...   \n","4    1.5. \"Dhrishtaketu, chekitana and the valiant ...   \n","..                                                 ...   \n","696  18.74 Sanjaya said  Thus I have heard this won...   \n","697  18.75 Through the grace of Vyasa I have heard ...   \n","698  18.76 O King, remembering this wonderful and h...   \n","699  18.77 And, remembering again and again, also t...   \n","700  18.78 Wherever is Krishna, the Lord of Yoga; w...   \n","\n","                                           WordMeaning  \n","0    1.1 धर्मक्षेत्रे on the holy plain? कुरुक्षेत्...  \n","1    1.2 दृष्ट्वा having seen? तु indeed? पाण्डवानी...  \n","2    1.3 पश्य behold? एताम् this? पाण्डुपुत्राणाम् ...  \n","3    1.4 अत्र here? शूराः heroes? महेष्वासाः mighty...  \n","4    1.5 धृष्टकेतुः Dhrishtaketu? चेकितानः Chekitan...  \n","..                                                 ...  \n","696  18.74 इति thus? अहम् I? वासुदेवस्य of Krishna?...  \n","697  18.75 व्यासप्रसादात् through the grace of Vyas...  \n","698  18.76 राजन् O King? संस्मृत्य having remembere...  \n","699  18.77 तत् that? च and? संस्मृत्य having rememb...  \n","700  18.78 यत्र wherever? योगेश्वरः the Lord of Yog...  \n","\n","[701 rows x 8 columns]"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import numpy as np\n","pd.read_csv(\"/kaggle/input/bhagwad-gita-dataset/Bhagwad_Gita.csv\")"]},{"cell_type":"markdown","id":"bef3fdde","metadata":{"papermill":{"duration":0.005421,"end_time":"2024-09-13T09:35:43.829875","exception":false,"start_time":"2024-09-13T09:35:43.824454","status":"completed"},"tags":[]},"source":["## Tokenization and Preparing Data for Model Training"]},{"cell_type":"code","execution_count":2,"id":"b8b5ac0c","metadata":{"execution":{"iopub.execute_input":"2024-09-13T09:35:43.842826Z","iopub.status.busy":"2024-09-13T09:35:43.842502Z","iopub.status.idle":"2024-09-13T09:36:01.217603Z","shell.execute_reply":"2024-09-13T09:36:01.2164Z"},"papermill":{"duration":17.38422,"end_time":"2024-09-13T09:36:01.219845","exception":false,"start_time":"2024-09-13T09:35:43.835625","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting data processing pipeline...\n","Loading and processing initial data...\n","Initial data processing completed. First few rows:\n","      ID  Chapter  Verse                                             Shloka  \\\n","0  BG1.1        1      1  धृतराष्ट्र उवाच |\\nधर्मक्षेत्रे कुरुक्षेत्रे स...   \n","1  BG1.2        1      2  सञ्जय उवाच |\\nदृष्ट्वा तु पाण्डवानीकं व्यूढं द...   \n","2  BG1.3        1      3  पश्यैतां पाण्डुपुत्राणामाचार्य महतीं चमूम् |\\n...   \n","3  BG1.4        1      4  अत्र शूरा महेष्वासा भीमार्जुनसमा युधि |\\nयुयुध...   \n","4  BG1.5        1      5  धृष्टकेतुश्चेकितानः काशिराजश्च वीर्यवान् |\\nपु...   \n","\n","                                     Transliteration  \\\n","0  dhṛtarāṣṭra uvāca .\\ndharmakṣetre kurukṣetre s...   \n","1  sañjaya uvāca .\\ndṛṣṭvā tu pāṇḍavānīkaṃ vyūḍha...   \n","2  paśyaitāṃ pāṇḍuputrāṇāmācārya mahatīṃ camūm .\\...   \n","3  atra śūrā maheṣvāsā bhīmārjunasamā yudhi .\\nyu...   \n","4  dhṛṣṭaketuścekitānaḥ kāśirājaśca vīryavān .\\np...   \n","\n","                                          HinMeaning  \\\n","0  ।।1.1।।धृतराष्ट्र ने कहा -- हे संजय ! धर्मभूमि...   \n","1  ।।1.2।।संजय ने कहा -- पाण्डव-सैन्य की व्यूह रच...   \n","2  ।।1.3।।हे आचार्य ! आपके बुद्धिमान शिष्य द्रुपद...   \n","3  ।।1.4।।इस सेना में महान् धनुर्धारी शूर योद्धा ...   \n","4  ।।1.5।।धृष्टकेतु, चेकितान, बलवान काशिराज,  पुर...   \n","\n","                                          EngMeaning  \\\n","0  1.1 Dhritarashtra said  What did my people and...   \n","1  1.2. Sanjaya said  Having seen the army of the...   \n","2  1.3. \"Behold, O Teacher! this mighty army of t...   \n","3  1.4. Here are heroes, mighty archers, eal in b...   \n","4  1.5. \"Dhrishtaketu, chekitana and the valiant ...   \n","\n","                                         WordMeaning  \n","0  1.1 धर्मक्षेत्रे on the holy plain? कुरुक्षेत्...  \n","1  1.2 दृष्ट्वा having seen? तु indeed? पाण्डवानी...  \n","2  1.3 पश्य behold? एताम् this? पाण्डुपुत्राणाम् ...  \n","3  1.4 अत्र here? शूराः heroes? महेष्वासाः mighty...  \n","4  1.5 धृष्टकेतुः Dhrishtaketu? चेकितानः Chekitan...  \n","Loading GPT-2 tokenizer...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c2583ce35d2f4ddab0cecc989624dd0c","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0939ee47a64d432699bd8afb67d54bbf","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d0351c58a2640d48c4cfae47b0d3f93","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d3ed0e717174a6aa23de9e8b7f7fddb","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a34740f5046448c49e85271e5bd407f3","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Converting DataFrame to Hugging Face Dataset...\n","Processing dataset...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f48e17139abc46839e5b2e095133275e","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/701 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Preparing GPT-2 examples...\n","Processed dataset size: 701\n","Sample processed data:\n","{'input_ids': [2484, 75, 17411, 25, 28225, 100, 24231, 225, 11976, 97, 11976, 108, 48077, 11976, 115, 24231, 235, 11976, 253, 24231, 235, 11976, 108, 28225, 231, 11976, 113, 48077, 11976, 248, 930, 198, 11976, 100, 11976, 108, 24231, 235, 11976, 106, 11976, 243, 24231, 235, 11976, 115, 24231, 229, 11976, 97, 24231, 235, 11976, 108, 24231, 229, 28225, 243, 24231, 223, 11976, 108, 24231, 223, 11976, 243, 24231, 235, 11976, 115, 24231, 229, 11976, 97, 24231, 235, 11976, 108, 24231, 229, 28225, 116, 11976, 106, 11976, 113, 24231, 229, 11976, 97, 48077, 28225, 107, 24231, 223, 11976, 107, 24231, 223, 11976, 97, 24231, 235, 11976, 116, 11976, 113, 11976, 225, 930, 198, 11976, 106, 48077, 11976, 106, 11976, 243, 48077, 11976, 225, 28225, 103, 48077, 11976, 96, 24231, 235, 11976, 94, 11976, 113, 48077, 11976, 114, 24231, 235, 11976, 248, 24231, 230, 11976, 113, 28225, 243, 11976, 123, 11976, 106, 11976, 243, 24231, 223, 11976, 108, 24231, 235, 11976, 113, 11976, 97, 28225, 116, 11976, 252, 24231, 235, 11976, 250, 11976, 107, 8614, 24231, 100, 12, 24231, 100, 15886, 198, 8291, 17201, 341, 25, 34590, 26292, 249, 18870, 10235, 26292, 96, 26292, 255, 430, 334, 85, 10235, 6888, 764, 198, 67, 29155, 461, 26292, 96, 316, 260, 479, 333, 2724, 26292, 96, 316, 260, 6072, 1015, 83, 10235, 331, 4669, 5500, 4170, 41585, 98, 764, 198, 76, 10235, 76, 461, 10235, 41585, 98, 279, 10235, 26292, 229, 41585, 235, 615, 10235, 129, 249, 6888, 12151, 479, 320, 461, 333, 85, 1045, 473, 12654, 73, 11729, 8614, 16, 12, 16, 15886, 198, 48313, 25, 352, 13, 16, 20529, 799, 283, 38535, 531, 220, 1867, 750, 616, 661, 290, 262, 11989, 286, 16492, 84, 466, 618, 484, 550, 16030, 198, 45525, 11069, 329, 3344, 319, 262, 11386, 8631, 286, 509, 14717, 591, 3202, 430, 11, 440, 2986, 73, 11729, 13, 198, 26449, 5308, 7574, 25, 352, 13, 16, 28225, 100, 11976, 108, 24231, 235, 11976, 106, 11976, 243, 24231, 235, 11976, 115, 24231, 229, 11976, 97, 24231, 235, 11976, 108, 24231, 229, 319, 262, 11386, 8631, 30, 28225, 243, 24231, 223, 11976, 108, 24231, 223, 11976, 243, 24231, 235, 11976, 115, 24231, 229, 11976, 97, 24231, 235, 11976, 108, 24231, 229, 287, 509, 14717, 591, 3202, 430, 30, 28225, 116, 11976, 106, 11976, 113, 24231, 229, 11976, 97, 48077, 11976, 225, 16030, 1978, 30, 28225, 107, 24231, 223, 11976, 107, 24231, 223, 11976, 97, 24231, 235, 11976, 116, 11976, 113, 11976, 225, 748, 343, 516, 284, 1907, 30, 28225, 106, 48077, 11976, 106, 11976, 243, 48077, 11976, 225, 616, 661, 30, 28225, 103, 48077, 11976, 96, 24231, 235, 11976, 94, 11976, 113, 48077, 11976, 225, 262, 11989, 286, 16492, 84, 30, 28225, 248, 290, 30, 28225, 237, 11976, 113, 635, 30, 28225, 243, 11976, 123, 11976, 106, 24231, 235, 644, 30, 28225, 227, 11976, 243, 24231, 223, 11976, 108, 24231, 235, 11976, 113, 11976, 97, 750, 466, 30, 28225, 116, 11976, 252, 24231, 235, 11976, 250, 11976, 107, 440, 2986, 73, 11729, 13, 21357, 560, 20529, 1670, 4730, 3202, 430, 1377, 326, 1295, 543, 17289], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [2484, 75, 17411, 25, 28225, 100, 24231, 225, 11976, 97, 11976, 108, 48077, 11976, 115, 24231, 235, 11976, 253, 24231, 235, 11976, 108, 28225, 231, 11976, 113, 48077, 11976, 248, 930, 198, 11976, 100, 11976, 108, 24231, 235, 11976, 106, 11976, 243, 24231, 235, 11976, 115, 24231, 229, 11976, 97, 24231, 235, 11976, 108, 24231, 229, 28225, 243, 24231, 223, 11976, 108, 24231, 223, 11976, 243, 24231, 235, 11976, 115, 24231, 229, 11976, 97, 24231, 235, 11976, 108, 24231, 229, 28225, 116, 11976, 106, 11976, 113, 24231, 229, 11976, 97, 48077, 28225, 107, 24231, 223, 11976, 107, 24231, 223, 11976, 97, 24231, 235, 11976, 116, 11976, 113, 11976, 225, 930, 198, 11976, 106, 48077, 11976, 106, 11976, 243, 48077, 11976, 225, 28225, 103, 48077, 11976, 96, 24231, 235, 11976, 94, 11976, 113, 48077, 11976, 114, 24231, 235, 11976, 248, 24231, 230, 11976, 113, 28225, 243, 11976, 123, 11976, 106, 11976, 243, 24231, 223, 11976, 108, 24231, 235, 11976, 113, 11976, 97, 28225, 116, 11976, 252, 24231, 235, 11976, 250, 11976, 107, 8614, 24231, 100, 12, 24231, 100, 15886, 198, 8291, 17201, 341, 25, 34590, 26292, 249, 18870, 10235, 26292, 96, 26292, 255, 430, 334, 85, 10235, 6888, 764, 198, 67, 29155, 461, 26292, 96, 316, 260, 479, 333, 2724, 26292, 96, 316, 260, 6072, 1015, 83, 10235, 331, 4669, 5500, 4170, 41585, 98, 764, 198, 76, 10235, 76, 461, 10235, 41585, 98, 279, 10235, 26292, 229, 41585, 235, 615, 10235, 129, 249, 6888, 12151, 479, 320, 461, 333, 85, 1045, 473, 12654, 73, 11729, 8614, 16, 12, 16, 15886, 198, 48313, 25, 352, 13, 16, 20529, 799, 283, 38535, 531, 220, 1867, 750, 616, 661, 290, 262, 11989, 286, 16492, 84, 466, 618, 484, 550, 16030, 198, 45525, 11069, 329, 3344, 319, 262, 11386, 8631, 286, 509, 14717, 591, 3202, 430, 11, 440, 2986, 73, 11729, 13, 198, 26449, 5308, 7574, 25, 352, 13, 16, 28225, 100, 11976, 108, 24231, 235, 11976, 106, 11976, 243, 24231, 235, 11976, 115, 24231, 229, 11976, 97, 24231, 235, 11976, 108, 24231, 229, 319, 262, 11386, 8631, 30, 28225, 243, 24231, 223, 11976, 108, 24231, 223, 11976, 243, 24231, 235, 11976, 115, 24231, 229, 11976, 97, 24231, 235, 11976, 108, 24231, 229, 287, 509, 14717, 591, 3202, 430, 30, 28225, 116, 11976, 106, 11976, 113, 24231, 229, 11976, 97, 48077, 11976, 225, 16030, 1978, 30, 28225, 107, 24231, 223, 11976, 107, 24231, 223, 11976, 97, 24231, 235, 11976, 116, 11976, 113, 11976, 225, 748, 343, 516, 284, 1907, 30, 28225, 106, 48077, 11976, 106, 11976, 243, 48077, 11976, 225, 616, 661, 30, 28225, 103, 48077, 11976, 96, 24231, 235, 11976, 94, 11976, 113, 48077, 11976, 225, 262, 11989, 286, 16492, 84, 30, 28225, 248, 290, 30, 28225, 237, 11976, 113, 635, 30, 28225, 243, 11976, 123, 11976, 106, 24231, 235, 644, 30, 28225, 227, 11976, 243, 24231, 223, 11976, 108, 24231, 235, 11976, 113, 11976, 97, 750, 466, 30, 28225, 116, 11976, 252, 24231, 235, 11976, 250, 11976, 107, 440, 2986, 73, 11729, 13, 21357, 560, 20529, 1670, 4730, 3202, 430, 1377, 326, 1295, 543, 17289]}\n","Saving processed dataset to disk...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c900b352b2ca4417962adfc254f9692d","version_major":2,"version_minor":0},"text/plain":["Saving the dataset (0/1 shards):   0%|          | 0/701 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Processed dataset saved to disk.\n","Data processing pipeline completed.\n"]}],"source":["import pandas as pd\n","from datasets import Dataset\n","from transformers import GPT2Tokenizer\n","\n","def load_and_process_data():\n","    # Load the Bhagwad Gita dataset from CSV\n","    print(\"Loading and processing initial data...\")\n","    df = pd.read_csv('/kaggle/input/bhagwad-gita-dataset/Bhagwad_Gita.csv')\n","    print(\"Initial data processing completed. First few rows:\")\n","    print(df.head())\n","    return df\n","\n","def load_tokenizer():\n","    # Initialize GPT-2 tokenizer and set pad token\n","    print(\"Loading GPT-2 tokenizer...\")\n","    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","    tokenizer.pad_token = tokenizer.eos_token  # GPT-2 doesn't have a pad token by default\n","    return tokenizer\n","\n","def prepare_gpt2_examples(examples, tokenizer):\n","    print(\"Preparing GPT-2 examples...\")\n","    input_ids_list = []\n","    attention_mask_list = []\n","    labels_list = []\n","\n","    for i in range(len(examples['Shloka'])):\n","        # Create prompt with the Shloka (Sanskrit verse)\n","        prompt = f\"Shloka: {examples['Shloka'][i]}\\nTransliteration: {examples['Transliteration'][i]}\\nTranslation: \"\n","\n","        # Choose the translation based on language\n","        english_translation = examples['EngMeaning'][i]\n","        hindi_translation = examples['HinMeaning'][i]\n","        word_meaning = examples['WordMeaning'][i]\n","\n","        # You can decide how to tokenize these translations.\n","        # Let's take English and Word meaning as the response.\n","        response = f\"{english_translation}\\nWordMeaning: {word_meaning}\"\n","\n","        # Tokenize both the prompt and response\n","        encoded = tokenizer(prompt + response, truncation=True, max_length=512, padding=\"max_length\")\n","\n","        # Prepare labels by copying input_ids and masking the padding tokens\n","        labels = encoded['input_ids'].copy()\n","        labels = [-100 if token == tokenizer.pad_token_id else token for token in labels]\n","\n","        input_ids_list.append(encoded['input_ids'])\n","        attention_mask_list.append(encoded['attention_mask'])\n","        labels_list.append(labels)\n","\n","    return {\n","        'input_ids': input_ids_list,\n","        'attention_mask': attention_mask_list,\n","        'labels': labels_list\n","    }\n","\n","def process_dataset(df, tokenizer):\n","    print(\"Converting DataFrame to Hugging Face Dataset...\")\n","    dataset = Dataset.from_pandas(df)\n","\n","    print(\"Processing dataset...\")\n","    processed_dataset = dataset.map(\n","        lambda examples: prepare_gpt2_examples(examples, tokenizer),\n","        batched=True,\n","        remove_columns=dataset.column_names\n","    )\n","\n","    print(f\"Processed dataset size: {len(processed_dataset)}\")\n","    print(\"Sample processed data:\")\n","    print(processed_dataset[0])\n","\n","    return processed_dataset\n","\n","def save_dataset(processed_dataset):\n","    print(\"Saving processed dataset to disk...\")\n","    processed_dataset.save_to_disk(\"processed_bhagavadgita_gpt2_dataset\")\n","    print(\"Processed dataset saved to disk.\")\n","\n","def main():\n","    print(\"Starting data processing pipeline...\")\n","    df = load_and_process_data()\n","    tokenizer = load_tokenizer()\n","    processed_dataset = process_dataset(df, tokenizer)\n","    save_dataset(processed_dataset)\n","    print(\"Data processing pipeline completed.\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","execution_count":3,"id":"7e75a591","metadata":{"execution":{"iopub.execute_input":"2024-09-13T09:36:01.238299Z","iopub.status.busy":"2024-09-13T09:36:01.237634Z","iopub.status.idle":"2024-09-13T09:36:02.318869Z","shell.execute_reply":"2024-09-13T09:36:02.317738Z"},"papermill":{"duration":1.093251,"end_time":"2024-09-13T09:36:02.321512","exception":false,"start_time":"2024-09-13T09:36:01.228261","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["__notebook__.ipynb  processed_bhagavadgita_gpt2_dataset\r\n"]}],"source":["!ls"]},{"cell_type":"markdown","id":"c6d81762","metadata":{"papermill":{"duration":0.007795,"end_time":"2024-09-13T09:36:02.337771","exception":false,"start_time":"2024-09-13T09:36:02.329976","status":"completed"},"tags":[]},"source":["# Verification of tokenization"]},{"cell_type":"code","execution_count":4,"id":"db5ce9e1","metadata":{"execution":{"iopub.execute_input":"2024-09-13T09:36:02.357176Z","iopub.status.busy":"2024-09-13T09:36:02.356466Z","iopub.status.idle":"2024-09-13T09:36:22.094325Z","shell.execute_reply":"2024-09-13T09:36:22.093292Z"},"papermill":{"duration":19.750795,"end_time":"2024-09-13T09:36:22.097453","exception":false,"start_time":"2024-09-13T09:36:02.346658","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading processed dataset...\n","Dataset size: 701\n","Dataset features: {'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n","\n","Input IDs: [2484, 75, 17411, 25, 28225, 101, 48077, 11976, 116, 24231, 235, 11976, 97, 11976, 123, 28225, 105, 24231, 223, 11976, 99, 24231, 235, 11976, 100, 11976, 123, 11976, 108, 11976, 107, 24231, 223, 11976, 243, 24231, 235, 11976, 97, 11976, 116, 24231, 235, 11976, 107, 28225, 101, 28225, 248, 48077, 11976, 107, 24231, 223, 11976, 243, 24231, 235, 11976, 97, 11976, 116, 24231, 235, 11976, 107, 28225, 255, 48077, 11976, 113, 11976, 101, 48077, 930, 198, 11976, 101, 28225, 248, 48077, 11976, 255, 48077, 11976, 113, 11976, 107, 11976, 97, 11976, 225, 28225, 114, 48077, 11976, 101, 24231, 235, 11976, 97, 11976, 123, 11976, 108, 11976, 114, 48077, 11976, 101, 24231, 235, 11976, 97, 11976, 116, 24231, 235, 11976, 107, 28225, 243, 24231, 223, 11976, 97, 11976, 225, 28225, 116, 24231, 223, 11976, 244, 11976, 106, 24231, 235, 8614, 24231, 101, 12, 24231, 105, 24231, 105, 15886, 198, 8291, 17201, 341, 25, 299, 10235, 301, 72, 3600, 34985, 343, 323, 2724, 83, 292, 3972, 12385, 269, 10235, 88, 2724, 83, 292, 3972, 275, 71, 10235, 10438, 10235, 764, 198, 2616, 269, 10235, 34369, 10235, 85, 323, 1045, 41585, 98, 25370, 249, 10235, 429, 8704, 129, 249, 10235, 429, 292, 3972, 479, 29822, 41585, 98, 424, 74, 2763, 8614, 17, 12, 2791, 15886, 198, 48313, 25, 362, 13, 2791, 1318, 318, 645, 3725, 286, 262, 12189, 284, 262, 15014, 1329, 88, 290, 284, 262, 15014, 1329, 88, 645, 16901, 318, 1744, 11, 290, 284, 262, 555, 1150, 12464, 612, 460, 307, 645, 4167, 11, 290, 284, 262, 582, 508, 468, 645, 4167, 11, 703, 460, 612, 307, 12157, 30, 198, 26449, 5308, 7574, 25, 362, 13, 2791, 28225, 101, 407, 30, 28225, 227, 11976, 116, 24231, 235, 11976, 97, 11976, 123, 318, 30, 28225, 105, 24231, 223, 11976, 99, 24231, 235, 11976, 100, 11976, 123, 11976, 225, 3725, 357, 1659, 262, 12189, 19427, 28225, 227, 11976, 107, 24231, 223, 11976, 243, 24231, 235, 11976, 97, 11976, 116, 24231, 235, 11976, 107, 286, 262, 15014, 1329, 88, 30, 28225, 101, 407, 30, 28225, 248, 290, 30, 28225, 227, 11976, 107, 24231, 223, 11976, 243, 24231, 235, 11976, 97, 11976, 116, 24231, 235, 11976, 107, 286, 262, 15014, 1329, 88, 30, 28225, 255, 48077, 11976, 113, 11976, 101, 48077, 16901, 30, 28225, 101, 407, 30, 28225, 248, 290, 30, 28225, 227, 11976, 255, 48077, 11976, 113, 11976, 107, 11976, 97, 11976, 225, 286, 262, 555, 1150, 13939, 30, 28225, 114, 48077, 11976, 101, 24231, 235, 11976, 97, 11976, 123, 11976, 225, 4167, 30, 28225, 227, 11976, 114, 48077, 11976, 101, 24231, 235, 11976, 97, 11976, 116, 24231, 235, 11976, 107, 286, 262, 41961, 5321, 30, 28225, 243, 24231, 223, 11976, 97, 11976, 225, 44012, 30, 28225, 116, 24231, 223, 11976, 244, 11976, 106, 24231, 235, 12157, 13, 21357, 560, 383, 582, 508, 2314, 4259, 465, 2000, 287, 16901, 2314, 423, 3725, 286, 262, 12189, 13, 383, 15014, 1329, 88, 582, 2314, 44811, 16901, 13, 679, 2314, 423, 772, 8157, 25808, 284, 12189, 45066, 4249, 460, 339, 423, 9482, 40314, 329, 22256, 393, 337, 482, 26270]\n","Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","Labels: [2484, 75, 17411, 25, 28225, 101, 48077, 11976, 116, 24231, 235, 11976, 97, 11976, 123, 28225, 105, 24231, 223, 11976, 99, 24231, 235, 11976, 100, 11976, 123, 11976, 108, 11976, 107, 24231, 223, 11976, 243, 24231, 235, 11976, 97, 11976, 116, 24231, 235, 11976, 107, 28225, 101, 28225, 248, 48077, 11976, 107, 24231, 223, 11976, 243, 24231, 235, 11976, 97, 11976, 116, 24231, 235, 11976, 107, 28225, 255, 48077, 11976, 113, 11976, 101, 48077, 930, 198, 11976, 101, 28225, 248, 48077, 11976, 255, 48077, 11976, 113, 11976, 107, 11976, 97, 11976, 225, 28225, 114, 48077, 11976, 101, 24231, 235, 11976, 97, 11976, 123, 11976, 108, 11976, 114, 48077, 11976, 101, 24231, 235, 11976, 97, 11976, 116, 24231, 235, 11976, 107, 28225, 243, 24231, 223, 11976, 97, 11976, 225, 28225, 116, 24231, 223, 11976, 244, 11976, 106, 24231, 235, 8614, 24231, 101, 12, 24231, 105, 24231, 105, 15886, 198, 8291, 17201, 341, 25, 299, 10235, 301, 72, 3600, 34985, 343, 323, 2724, 83, 292, 3972, 12385, 269, 10235, 88, 2724, 83, 292, 3972, 275, 71, 10235, 10438, 10235, 764, 198, 2616, 269, 10235, 34369, 10235, 85, 323, 1045, 41585, 98, 25370, 249, 10235, 429, 8704, 129, 249, 10235, 429, 292, 3972, 479, 29822, 41585, 98, 424, 74, 2763, 8614, 17, 12, 2791, 15886, 198, 48313, 25, 362, 13, 2791, 1318, 318, 645, 3725, 286, 262, 12189, 284, 262, 15014, 1329, 88, 290, 284, 262, 15014, 1329, 88, 645, 16901, 318, 1744, 11, 290, 284, 262, 555, 1150, 12464, 612, 460, 307, 645, 4167, 11, 290, 284, 262, 582, 508, 468, 645, 4167, 11, 703, 460, 612, 307, 12157, 30, 198, 26449, 5308, 7574, 25, 362, 13, 2791, 28225, 101, 407, 30, 28225, 227, 11976, 116, 24231, 235, 11976, 97, 11976, 123, 318, 30, 28225, 105, 24231, 223, 11976, 99, 24231, 235, 11976, 100, 11976, 123, 11976, 225, 3725, 357, 1659, 262, 12189, 19427, 28225, 227, 11976, 107, 24231, 223, 11976, 243, 24231, 235, 11976, 97, 11976, 116, 24231, 235, 11976, 107, 286, 262, 15014, 1329, 88, 30, 28225, 101, 407, 30, 28225, 248, 290, 30, 28225, 227, 11976, 107, 24231, 223, 11976, 243, 24231, 235, 11976, 97, 11976, 116, 24231, 235, 11976, 107, 286, 262, 15014, 1329, 88, 30, 28225, 255, 48077, 11976, 113, 11976, 101, 48077, 16901, 30, 28225, 101, 407, 30, 28225, 248, 290, 30, 28225, 227, 11976, 255, 48077, 11976, 113, 11976, 107, 11976, 97, 11976, 225, 286, 262, 555, 1150, 13939, 30, 28225, 114, 48077, 11976, 101, 24231, 235, 11976, 97, 11976, 123, 11976, 225, 4167, 30, 28225, 227, 11976, 114, 48077, 11976, 101, 24231, 235, 11976, 97, 11976, 116, 24231, 235, 11976, 107, 286, 262, 41961, 5321, 30, 28225, 243, 24231, 223, 11976, 97, 11976, 225, 44012, 30, 28225, 116, 24231, 223, 11976, 244, 11976, 106, 24231, 235, 12157, 13, 21357, 560, 383, 582, 508, 2314, 4259, 465, 2000, 287, 16901, 2314, 423, 3725, 286, 262, 12189, 13, 383, 15014, 1329, 88, 582, 2314, 44811, 16901, 13, 679, 2314, 423, 772, 8157, 25808, 284, 12189, 45066, 4249, 460, 339, 423, 9482, 40314, 329, 22256, 393, 337, 482, 26270]\n","Decoded Input (Prompt + Response): Shloka: नास्ति बुद्धिरयुक्तस्य न चायुक्तस्य भावना |\n","न चाभावयतः शान्तिरशान्तस्य कुतः सुखम् ||२-६६||\n","Transliteration: nāsti buddhirayuktasya na cāyuktasya bhāvanā.\n","na cābhāvayataḥ śāntiraśāntasya kutaḥ sukham ||2-66||\n","Translation: 2.66 There is no knowledge of the Self to the unsteady and to the unsteady no meditation is possible, and to the unmeditative there can be no peace, and to the man who has no peace, how can there be happiness?\n","WordMeaning: 2.66 न not? अस्ति is? बुद्धिः knowledge (of the Self)? अयुक्तस्य of the unsteady? न not? च and? अयुक्तस्य of the unsteady? भावना meditation? न not? च and? अभावयतः of the unmeditated? शान्तिः peace? अशान्तस्य of the peaceless? कुतः whence? सुखम् happiness.Commentary The man who cannot fix his mind in meditation cannot have knowledge of the Self. The unsteady man cannot practise meditation. He cannot have even intense devotion to Selfknowledge nor can he have burning longing for liberation or Moksha\n","Decoded Labels (Response): Shloka: नास्ति बुद्धिरयुक्तस्य न चायुक्तस्य भावना |\n","न चाभावयतः शान्तिरशान्तस्य कुतः सुखम् ||२-६६||\n","Transliteration: nāsti buddhirayuktasya na cāyuktasya bhāvanā.\n","na cābhāvayataḥ śāntiraśāntasya kutaḥ sukham ||2-66||\n","Translation: 2.66 There is no knowledge of the Self to the unsteady and to the unsteady no meditation is possible, and to the unmeditative there can be no peace, and to the man who has no peace, how can there be happiness?\n","WordMeaning: 2.66 न not? अस्ति is? बुद्धिः knowledge (of the Self)? अयुक्तस्य of the unsteady? न not? च and? अयुक्तस्य of the unsteady? भावना meditation? न not? च and? अभावयतः of the unmeditated? शान्तिः peace? अशान्तस्य of the peaceless? कुतः whence? सुखम् happiness.Commentary The man who cannot fix his mind in meditation cannot have knowledge of the Self. The unsteady man cannot practise meditation. He cannot have even intense devotion to Selfknowledge nor can he have burning longing for liberation or Moksha\n","\n","--------------------------------------------------\n","\n","Input IDs: [2484, 75, 17411, 25, 28225, 228, 11976, 103, 24231, 224, 11976, 108, 24231, 235, 11976, 107, 11976, 106, 48077, 11976, 96, 11976, 106, 11976, 248, 11976, 110, 11976, 103, 24231, 235, 11976, 108, 11976, 97, 11976, 123, 11976, 115, 24231, 235, 11976, 254, 11976, 224, 198, 11976, 116, 11976, 106, 24231, 223, 11976, 99, 24231, 235, 11976, 108, 11976, 106, 48077, 11976, 103, 11976, 225, 28225, 103, 24231, 235, 11976, 108, 11976, 113, 11976, 123, 11976, 114, 11976, 101, 24231, 235, 11976, 97, 11976, 123, 28225, 107, 11976, 99, 24231, 235, 11976, 113, 11976, 97, 24231, 235, 930, 198, 11976, 97, 11976, 99, 24231, 235, 11976, 113, 11976, 97, 24231, 235, 11976, 243, 48077, 11976, 106, 48077, 28225, 107, 11976, 224, 28225, 103, 24231, 235, 11976, 108, 11976, 113, 11976, 123, 11976, 114, 11976, 101, 24231, 235, 11976, 97, 11976, 123, 28225, 116, 11976, 108, 24231, 235, 11976, 113, 24231, 229, 198, 11976, 116, 28225, 114, 48077, 11976, 101, 24231, 235, 11976, 97, 11976, 123, 11976, 106, 48077, 11976, 103, 24231, 235, 11976, 101, 24231, 233, 11976, 97, 11976, 123, 28225, 101, 28225, 243, 48077, 11976, 106, 11976, 243, 48077, 11976, 106, 24231, 222, 8614, 24231, 101, 12, 24231, 255, 24231, 99, 15886, 198, 8291, 17201, 341, 25, 220, 10235, 79, 20317, 563, 321, 10235, 26292, 229, 11494, 282, 499, 81, 7246, 26292, 96, 26292, 255, 3099, 26292, 225, 6072, 463, 859, 10235, 8957, 41585, 98, 279, 4108, 72, 129, 249, 17096, 331, 32225, 265, 764, 198, 83, 32225, 265, 74, 10235, 76, 10235, 21349, 26292, 225, 279, 4108, 72, 129, 249, 17096, 29008, 303, 473, 25370, 249, 10235, 429, 320, 10235, 79, 1662, 72, 12385, 479, 10235, 76, 461, 10235, 76, 18962, 8614, 17, 12, 2154, 15886, 198, 48313, 25, 362, 13, 2154, 679, 708, 1299, 4167, 656, 4150, 477, 15997, 3802, 355, 10150, 3802, 262, 9151, 543, 11, 5901, 422, 477, 5389, 11, 3793, 21303, 2668, 26, 475, 407, 262, 582, 508, 318, 1336, 286, 15997, 13, 198, 26449, 5308, 7574, 25, 362, 13, 2154, 28225, 228, 11976, 103, 24231, 224, 11976, 108, 24231, 235, 11976, 107, 11976, 106, 48077, 11976, 96, 11976, 106, 24231, 235, 5901, 422, 477, 5389, 30, 28225, 227, 11976, 248, 11976, 110, 11976, 103, 24231, 235, 11976, 108, 11976, 97, 11976, 123, 11976, 115, 24231, 235, 11976, 254, 11976, 106, 24231, 235, 1912, 287, 991, 1108, 30, 28225, 116, 11976, 106, 24231, 223, 11976, 99, 24231, 235, 11976, 108, 11976, 106, 24231, 235, 9151, 30, 28225, 228, 11976, 103, 11976, 225, 1660, 30, 28225, 103, 24231, 235, 11976, 108, 11976, 113, 11976, 123, 11976, 114, 11976, 101, 24231, 235, 11976, 97, 11976, 123, 3802, 30, 28225, 107, 11976, 99, 24231, 235, 11976, 113, 11976, 97, 24231, 235, 355, 30, 28225, 97, 11976, 99, 24231, 235, 11976, 113, 11976, 97, 24231, 235, 523, 30, 28225, 243, 48077, 11976, 106, 48077, 11976, 225, 15997, 30, 28225, 107, 11976, 106, 24231, 235, 4150, 30, 28225, 103, 24231, 235, 11976, 108, 11976, 113, 11976, 123, 11976, 114, 11976, 101, 24231, 235, 11976, 97, 11976, 123, 3802, 30, 28225, 116]\n","Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","Labels: [2484, 75, 17411, 25, 28225, 228, 11976, 103, 24231, 224, 11976, 108, 24231, 235, 11976, 107, 11976, 106, 48077, 11976, 96, 11976, 106, 11976, 248, 11976, 110, 11976, 103, 24231, 235, 11976, 108, 11976, 97, 11976, 123, 11976, 115, 24231, 235, 11976, 254, 11976, 224, 198, 11976, 116, 11976, 106, 24231, 223, 11976, 99, 24231, 235, 11976, 108, 11976, 106, 48077, 11976, 103, 11976, 225, 28225, 103, 24231, 235, 11976, 108, 11976, 113, 11976, 123, 11976, 114, 11976, 101, 24231, 235, 11976, 97, 11976, 123, 28225, 107, 11976, 99, 24231, 235, 11976, 113, 11976, 97, 24231, 235, 930, 198, 11976, 97, 11976, 99, 24231, 235, 11976, 113, 11976, 97, 24231, 235, 11976, 243, 48077, 11976, 106, 48077, 28225, 107, 11976, 224, 28225, 103, 24231, 235, 11976, 108, 11976, 113, 11976, 123, 11976, 114, 11976, 101, 24231, 235, 11976, 97, 11976, 123, 28225, 116, 11976, 108, 24231, 235, 11976, 113, 24231, 229, 198, 11976, 116, 28225, 114, 48077, 11976, 101, 24231, 235, 11976, 97, 11976, 123, 11976, 106, 48077, 11976, 103, 24231, 235, 11976, 101, 24231, 233, 11976, 97, 11976, 123, 28225, 101, 28225, 243, 48077, 11976, 106, 11976, 243, 48077, 11976, 106, 24231, 222, 8614, 24231, 101, 12, 24231, 255, 24231, 99, 15886, 198, 8291, 17201, 341, 25, 220, 10235, 79, 20317, 563, 321, 10235, 26292, 229, 11494, 282, 499, 81, 7246, 26292, 96, 26292, 255, 3099, 26292, 225, 6072, 463, 859, 10235, 8957, 41585, 98, 279, 4108, 72, 129, 249, 17096, 331, 32225, 265, 764, 198, 83, 32225, 265, 74, 10235, 76, 10235, 21349, 26292, 225, 279, 4108, 72, 129, 249, 17096, 29008, 303, 473, 25370, 249, 10235, 429, 320, 10235, 79, 1662, 72, 12385, 479, 10235, 76, 461, 10235, 76, 18962, 8614, 17, 12, 2154, 15886, 198, 48313, 25, 362, 13, 2154, 679, 708, 1299, 4167, 656, 4150, 477, 15997, 3802, 355, 10150, 3802, 262, 9151, 543, 11, 5901, 422, 477, 5389, 11, 3793, 21303, 2668, 26, 475, 407, 262, 582, 508, 318, 1336, 286, 15997, 13, 198, 26449, 5308, 7574, 25, 362, 13, 2154, 28225, 228, 11976, 103, 24231, 224, 11976, 108, 24231, 235, 11976, 107, 11976, 106, 48077, 11976, 96, 11976, 106, 24231, 235, 5901, 422, 477, 5389, 30, 28225, 227, 11976, 248, 11976, 110, 11976, 103, 24231, 235, 11976, 108, 11976, 97, 11976, 123, 11976, 115, 24231, 235, 11976, 254, 11976, 106, 24231, 235, 1912, 287, 991, 1108, 30, 28225, 116, 11976, 106, 24231, 223, 11976, 99, 24231, 235, 11976, 108, 11976, 106, 24231, 235, 9151, 30, 28225, 228, 11976, 103, 11976, 225, 1660, 30, 28225, 103, 24231, 235, 11976, 108, 11976, 113, 11976, 123, 11976, 114, 11976, 101, 24231, 235, 11976, 97, 11976, 123, 3802, 30, 28225, 107, 11976, 99, 24231, 235, 11976, 113, 11976, 97, 24231, 235, 355, 30, 28225, 97, 11976, 99, 24231, 235, 11976, 113, 11976, 97, 24231, 235, 523, 30, 28225, 243, 48077, 11976, 106, 48077, 11976, 225, 15997, 30, 28225, 107, 11976, 106, 24231, 235, 4150, 30, 28225, 103, 24231, 235, 11976, 108, 11976, 113, 11976, 123, 11976, 114, 11976, 101, 24231, 235, 11976, 97, 11976, 123, 3802, 30, 28225, 116]\n","Decoded Input (Prompt + Response): Shloka: आपूर्यमाणमचलप्रतिष्ठं\n","समुद्रमापः प्रविशन्ति यद्वत् |\n","तद्वत्कामा यं प्रविशन्ति सर्वे\n","स शान्तिमाप्नोति न कामकामी ||२-७०||\n","Transliteration: āpūryamāṇamacalapratiṣṭhaṃ samudramāpaḥ praviśanti yadvat.\n","tadvatkāmā yaṃ praviśanti sarve sa śāntimāpnoti na kāmakāmī ||2-70||\n","Translation: 2.70 He attains peace into whom all desires enter as waters enter the ocean which, filled from all sides, remains unmoved; but not the man who is full of desires.\n","WordMeaning: 2.70 आपूर्यमाणम् filled from all sides? अचलप्रतिष्ठम् based in stillness? समुद्रम् ocean? आपः water? प्रविशन्ति enter? यद्वत् as? तद्वत् so? कामाः desires? यम् whom? प्रविशन्ति enter? स\n","Decoded Labels (Response): Shloka: आपूर्यमाणमचलप्रतिष्ठं\n","समुद्रमापः प्रविशन्ति यद्वत् |\n","तद्वत्कामा यं प्रविशन्ति सर्वे\n","स शान्तिमाप्नोति न कामकामी ||२-७०||\n","Transliteration: āpūryamāṇamacalapratiṣṭhaṃ samudramāpaḥ praviśanti yadvat.\n","tadvatkāmā yaṃ praviśanti sarve sa śāntimāpnoti na kāmakāmī ||2-70||\n","Translation: 2.70 He attains peace into whom all desires enter as waters enter the ocean which, filled from all sides, remains unmoved; but not the man who is full of desires.\n","WordMeaning: 2.70 आपूर्यमाणम् filled from all sides? अचलप्रतिष्ठम् based in stillness? समुद्रम् ocean? आपः water? प्रविशन्ति enter? यद्वत् as? तद्वत् so? कामाः desires? यम् whom? प्रविशन्ति enter? स\n","\n","--------------------------------------------------\n","\n","Tokenization verification complete.\n"]}],"source":["import random\n","from datasets import load_from_disk\n","from transformers import GPT2Tokenizer\n","\n","def display_sample(sample, tokenizer):\n","    print(\"Input IDs:\", sample['input_ids'])\n","    print(\"Attention Mask:\", sample['attention_mask'])\n","    print(\"Labels:\", sample['labels'])\n","\n","    # Decode the input IDs back into text\n","    decoded_input = tokenizer.decode(sample['input_ids'], skip_special_tokens=True)\n","    print(\"Decoded Input (Prompt + Response):\", decoded_input)\n","    \n","    # Decode the labels back into text (ignore padding or masked tokens)\n","    decoded_labels = tokenizer.decode([label for label in sample['labels'] if label != -100], skip_special_tokens=True)\n","    print(\"Decoded Labels (Response):\", decoded_labels)\n","    print(\"\\n\" + \"-\"*50 + \"\\n\")\n","\n","def main():\n","    # Load the processed dataset from disk\n","    print(\"Loading processed dataset...\")\n","    dataset = load_from_disk(\"processed_bhagavadgita_gpt2_dataset\")\n","\n","    # Load the GPT-2 tokenizer\n","    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","    tokenizer.pad_token = tokenizer.eos_token  # GPT-2 doesn't have a pad token by default\n","\n","    # Display information about the dataset\n","    print(f\"Dataset size: {len(dataset)}\")\n","    print(f\"Dataset features: {dataset.features}\\n\")\n","\n","    # Display a few random samples from the dataset\n","    num_samples = 2  # You can change this to view more samples\n","    random_indices = random.sample(range(len(dataset)), num_samples)\n","\n","    for idx in random_indices:\n","        sample = dataset[idx]\n","        display_sample(sample, tokenizer)\n","\n","    print(\"Tokenization verification complete.\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","execution_count":5,"id":"61c8f336","metadata":{"execution":{"iopub.execute_input":"2024-09-13T09:36:22.11688Z","iopub.status.busy":"2024-09-13T09:36:22.115998Z","iopub.status.idle":"2024-09-13T09:36:22.233389Z","shell.execute_reply":"2024-09-13T09:36:22.232445Z"},"papermill":{"duration":0.129359,"end_time":"2024-09-13T09:36:22.235658","exception":false,"start_time":"2024-09-13T09:36:22.106299","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CUDA available: True\n","Number of GPUs: 2\n"]}],"source":["import torch\n","print(f\"CUDA available: {torch.cuda.is_available()}\")\n","print(f\"Number of GPUs: {torch.cuda.device_count()}\")"]},{"cell_type":"code","execution_count":6,"id":"1cad9282","metadata":{"execution":{"iopub.execute_input":"2024-09-13T09:36:22.254113Z","iopub.status.busy":"2024-09-13T09:36:22.253777Z","iopub.status.idle":"2024-09-13T09:36:22.263635Z","shell.execute_reply":"2024-09-13T09:36:22.262766Z"},"papermill":{"duration":0.021393,"end_time":"2024-09-13T09:36:22.265556","exception":false,"start_time":"2024-09-13T09:36:22.244163","status":"completed"},"tags":[]},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def plot_training_loss(losses, output_file='training_loss_curve.png'):\n","    if not losses:\n","        print(\"No loss data available for plotting.\")\n","        return\n","\n","    # Convert losses to numpy array for easier manipulation\n","    losses = np.array(losses)\n","\n","    # Remove any potential NaN or inf values\n","    losses = losses[np.isfinite(losses)]\n","\n","    if len(losses) == 0:\n","        print(\"No valid loss data available for plotting after removing NaN/inf values.\")\n","        return\n","\n","    steps = range(1, len(losses) + 1)\n","\n","    # Debug: print losses and steps for verification\n","    print(f\"Number of losses: {len(losses)}\")\n","    print(f\"Losses: {losses}\")\n","    \n","    plt.figure(figsize=(10, 5))\n","    plt.plot(steps, losses, label='Training Loss')\n","    plt.xlabel('Steps')\n","    plt.ylabel('Loss')\n","    plt.title('Training Loss Curve')\n","    plt.legend()\n","\n","    # Set y-axis to logarithmic scale if the loss varies over several orders of magnitude\n","    if np.log10(losses.max()) - np.log10(losses.min()) > 2:\n","        plt.yscale('log')\n","\n","    # Add grid for better readability\n","    plt.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n","\n","    try:\n","        plt.savefig(output_file)\n","        print(f\"Learning and loss curve has been plotted and saved to {output_file}\")\n","    except Exception as e:\n","        print(f\"Error saving the plot: {e}\")\n","    finally:\n","        plt.close()\n"]},{"cell_type":"markdown","id":"1bf177d5","metadata":{"papermill":{"duration":0.008137,"end_time":"2024-09-13T09:36:22.281973","exception":false,"start_time":"2024-09-13T09:36:22.273836","status":"completed"},"tags":[]},"source":["## Training the GPT-2 Model:  and Evaluation and Model Generation:"]},{"cell_type":"code","execution_count":7,"id":"1339712a","metadata":{"execution":{"iopub.execute_input":"2024-09-13T09:36:22.300212Z","iopub.status.busy":"2024-09-13T09:36:22.299867Z","iopub.status.idle":"2024-09-13T09:47:10.618675Z","shell.execute_reply":"2024-09-13T09:47:10.610101Z"},"papermill":{"duration":648.381481,"end_time":"2024-09-13T09:47:10.671638","exception":false,"start_time":"2024-09-13T09:36:22.290157","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading processed dataset...\n","Initializing model and tokenizer...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef90ab0aa5bd433398edc4ac5407fa5d","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"45b42dbd420741f88d35ce5041d45c6d","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","Using auto half precision backend\n"]},{"name":"stdout","output_type":"stream","text":["Training the model...\n"]},{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 560\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 2\n","  Training with DataParallel so batch size has been adjusted to: 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 4\n","  Total optimization steps = 350\n","  Number of trainable parameters = 124,439,808\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [350/350 09:48, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./results/checkpoint-350\n","Configuration saved in ./results/checkpoint-350/config.json\n","Configuration saved in ./results/checkpoint-350/generation_config.json\n","Model weights saved in ./results/checkpoint-350/model.safetensors\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Saving model checkpoint to ./bhagavadgita_gpt2_model\n","Configuration saved in ./bhagavadgita_gpt2_model/config.json\n","Configuration saved in ./bhagavadgita_gpt2_model/generation_config.json\n"]},{"name":"stdout","output_type":"stream","text":["Saving the trained model...\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in ./bhagavadgita_gpt2_model/model.safetensors\n","\n","***** Running Evaluation *****\n","  Num examples = 141\n","  Batch size = 4\n"]},{"name":"stdout","output_type":"stream","text":["Evaluating the model...\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","***** Running Prediction *****\n","  Num examples = 8\n","  Batch size = 4\n"]},{"name":"stdout","output_type":"stream","text":["Evaluation results: {'eval_loss': 1.5589011907577515, 'eval_runtime': 5.9872, 'eval_samples_per_second': 23.55, 'eval_steps_per_second': 6.013, 'epoch': 10.0}\n","Running prediction...\n","0\n"]},{"name":"stderr","output_type":"stream","text":["\n","***** Running Prediction *****\n","  Num examples = 8\n","  Batch size = 4\n"]},{"name":"stdout","output_type":"stream","text":["8\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","***** Running Prediction *****\n","  Num examples = 8\n","  Batch size = 4\n"]},{"name":"stdout","output_type":"stream","text":["16\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","***** Running Prediction *****\n","  Num examples = 8\n","  Batch size = 4\n"]},{"name":"stdout","output_type":"stream","text":["24\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","***** Running Prediction *****\n","  Num examples = 8\n","  Batch size = 4\n"]},{"name":"stdout","output_type":"stream","text":["32\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","***** Running Prediction *****\n","  Num examples = 8\n","  Batch size = 4\n"]},{"name":"stdout","output_type":"stream","text":["40\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","***** Running Prediction *****\n","  Num examples = 8\n","  Batch size = 4\n"]},{"name":"stdout","output_type":"stream","text":["48\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","***** Running Prediction *****\n","  Num examples = 8\n","  Batch size = 4\n"]},{"name":"stdout","output_type":"stream","text":["56\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","***** Running Prediction *****\n","  Num examples = 8\n","  Batch size = 4\n"]},{"name":"stdout","output_type":"stream","text":["64\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","***** Running Prediction *****\n","  Num examples = 8\n","  Batch size = 4\n"]},{"name":"stdout","output_type":"stream","text":["72\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","***** Running Prediction *****\n","  Num examples = 8\n","  Batch size = 4\n"]},{"name":"stdout","output_type":"stream","text":["80\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","***** Running Prediction *****\n","  Num examples = 8\n","  Batch size = 4\n"]},{"name":"stdout","output_type":"stream","text":["88\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","***** Running Prediction *****\n","  Num examples = 8\n","  Batch size = 4\n"]},{"name":"stdout","output_type":"stream","text":["96\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","***** Running Prediction *****\n","  Num examples = 8\n","  Batch size = 4\n"]},{"name":"stdout","output_type":"stream","text":["104\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","***** Running Prediction *****\n","  Num examples = 8\n","  Batch size = 4\n"]},{"name":"stdout","output_type":"stream","text":["112\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","***** Running Prediction *****\n","  Num examples = 8\n","  Batch size = 4\n"]},{"name":"stdout","output_type":"stream","text":["120\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","***** Running Prediction *****\n","  Num examples = 8\n","  Batch size = 4\n"]},{"name":"stdout","output_type":"stream","text":["128\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","***** Running Prediction *****\n","  Num examples = 5\n","  Batch size = 4\n"]},{"name":"stdout","output_type":"stream","text":["136\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Test results shape: (141, 512, 50257)\n","Training complete. Model saved to ./bhagavadgita_gpt2_model\n","Learning and loss curves have been plotted and saved.\n"]}],"source":["from transformers import GPT2LMHeadModel, TrainingArguments, Trainer, GPT2Tokenizer, EarlyStoppingCallback, TrainerCallback\n","from datasets import load_from_disk\n","import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Define a callback class to log training loss\n","class LogCallback(TrainerCallback):\n","    def __init__(self):\n","        self.losses = []\n","\n","    def on_log(self, args, state, control, logs=None, **kwargs):\n","        if logs.get(\"loss\") is not None:\n","            self.losses.append(logs[\"loss\"])\n","\n","def main():\n","    # Load the processed dataset\n","    print(\"Loading processed dataset...\")\n","    dataset = load_from_disk(\"processed_bhagavadgita_gpt2_dataset\")\n","\n","    # Split the dataset into training and validation sets\n","    dataset = dataset.train_test_split(test_size=0.2)\n","\n","    # Initialize the model and tokenizer\n","    print(\"Initializing model and tokenizer...\")\n","    model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","    tokenizer.pad_token = tokenizer.eos_token  # Set pad token to EOS for GPT-2\n","    \n","    # Define training arguments with memory optimization\n","    training_args = TrainingArguments(\n","        output_dir=\"./results\",\n","        num_train_epochs=10,\n","        learning_rate=5e-5,\n","        per_device_train_batch_size=2,  \n","        per_device_eval_batch_size=2,  \n","        gradient_accumulation_steps=4,  # Simulate larger batch size via accumulation\n","        warmup_steps=500,\n","        weight_decay=0.01,\n","        logging_dir=\"./logs\",\n","        logging_steps=200,  \n","        evaluation_strategy=\"steps\",\n","        eval_steps=500,\n","        save_steps=1000,\n","        load_best_model_at_end=True,\n","        metric_for_best_model=\"eval_loss\",\n","        greater_is_better=False,\n","        log_level=\"info\", \n","        fp16=True,  # Enable mixed precision to save memory\n","        save_total_limit=2,  # Limit number of saved checkpoints\n","        report_to=\"none\",  \n","        lr_scheduler_type=\"cosine\"\n","    )\n","\n","    # Define a custom data collator\n","    def data_collator(features):\n","        # Extract the input_ids and attention_mask from the dataset\n","        input_ids = torch.tensor([f[\"input_ids\"] for f in features])\n","        attention_mask = torch.tensor([f[\"attention_mask\"] for f in features])\n","        labels = torch.tensor([f[\"labels\"] for f in features])\n","\n","        return {\n","            \"input_ids\": input_ids,\n","            \"attention_mask\": attention_mask,\n","            \"labels\": labels\n","        }\n","\n","    # Initialize LogCallback to capture the loss during training\n","    log_callback = LogCallback()\n","\n","    # Initialize Trainer\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=dataset[\"train\"],\n","        eval_dataset=dataset[\"test\"],\n","        data_collator=data_collator,\n","        callbacks=[EarlyStoppingCallback(early_stopping_patience=3), log_callback]  # Add custom log callback\n","    )\n","\n","    # Clear CUDA cache before training to free up memory\n","    torch.cuda.empty_cache()\n","\n","    # Train the model\n","    print(\"Training the model...\")\n","    train_result = trainer.train()\n","\n","    # Save the trained model\n","    print(\"Saving the trained model...\")\n","    trainer.save_model(\"./bhagavadgita_gpt2_model\")\n","\n","    # After training\n","    print(\"Evaluating the model...\")\n","    eval_results = trainer.evaluate()\n","    print(f\"Evaluation results: {eval_results}\")\n","\n","    print(\"Running prediction...\")\n","    # Custom prediction function to handle OOM errors\n","    def predict_in_batches(dataset, batch_size=8):\n","        all_predictions = []\n","        for i in range(0, len(dataset), batch_size):\n","            print(i)\n","            batch = dataset.select(range(i, min(i + batch_size, len(dataset))))\n","            with torch.no_grad():\n","                outputs = trainer.predict(batch)\n","            all_predictions.append(outputs.predictions)\n","            torch.cuda.empty_cache()  # Clear GPU memory after each batch\n","        return np.concatenate(all_predictions, axis=0)\n","\n","    test_results = predict_in_batches(dataset[\"test\"])\n","    print(f\"Test results shape: {test_results.shape}\")\n","\n","    print(\"Training complete. Model saved to ./bhagavadgita_gpt2_model\")\n","    #plot_training_loss(log_callback.losses)\n","\n","    print(\"Learning and loss curves have been plotted and saved.\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","execution_count":8,"id":"49a67ed1","metadata":{"execution":{"iopub.execute_input":"2024-09-13T09:47:10.715271Z","iopub.status.busy":"2024-09-13T09:47:10.713994Z","iopub.status.idle":"2024-09-13T09:47:12.894787Z","shell.execute_reply":"2024-09-13T09:47:12.893651Z"},"papermill":{"duration":2.204871,"end_time":"2024-09-13T09:47:12.897131","exception":false,"start_time":"2024-09-13T09:47:10.69226","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid, fd = os.forkpty()\n"]},{"name":"stdout","output_type":"stream","text":["__notebook__.ipynb\t processed_bhagavadgita_gpt2_dataset\r\n","bhagavadgita_gpt2_model  results\r\n"]}],"source":["#! rm training_loss_curve.png\n","!ls"]},{"cell_type":"code","execution_count":9,"id":"d3649596","metadata":{"execution":{"iopub.execute_input":"2024-09-13T09:47:12.938084Z","iopub.status.busy":"2024-09-13T09:47:12.937723Z","iopub.status.idle":"2024-09-13T09:47:12.945382Z","shell.execute_reply":"2024-09-13T09:47:12.94436Z"},"papermill":{"duration":0.030451,"end_time":"2024-09-13T09:47:12.947461","exception":false,"start_time":"2024-09-13T09:47:12.91701","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["\"\\nimport matplotlib.pyplot as plt\\nimport matplotlib.image as mpimg\\n\\n# Load and display the saved plot image\\nimg = mpimg.imread('training_loss_curve.png')\\nplt.figure(figsize=(10, 5))\\nplt.imshow(img)\\nplt.axis('off')  # Hide axis labels for a cleaner display\\nplt.show()\\n\""]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","# Load and display the saved plot image\n","img = mpimg.imread('training_loss_curve.png')\n","plt.figure(figsize=(10, 5))\n","plt.imshow(img)\n","plt.axis('off')  # Hide axis labels for a cleaner display\n","plt.show()\n","'''"]},{"cell_type":"markdown","id":"ba4eafb3","metadata":{"papermill":{"duration":0.019247,"end_time":"2024-09-13T09:47:12.986783","exception":false,"start_time":"2024-09-13T09:47:12.967536","status":"completed"},"tags":[]},"source":["## Model testing"]},{"cell_type":"code","execution_count":10,"id":"3d882baf","metadata":{"execution":{"iopub.execute_input":"2024-09-13T09:47:13.029211Z","iopub.status.busy":"2024-09-13T09:47:13.028218Z","iopub.status.idle":"2024-09-13T09:47:29.990211Z","shell.execute_reply":"2024-09-13T09:47:29.989043Z"},"papermill":{"duration":16.986074,"end_time":"2024-09-13T09:47:29.992485","exception":false,"start_time":"2024-09-13T09:47:13.006411","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file ./bhagavadgita_gpt2_model/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.44.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file ./bhagavadgita_gpt2_model/model.safetensors\n"]},{"name":"stdout","output_type":"stream","text":["Loading the fine-tuned model...\n"]},{"name":"stderr","output_type":"stream","text":["Generate config GenerationConfig {\n","  \"bos_token_id\": 50256,\n","  \"eos_token_id\": 50256\n","}\n","\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./bhagavadgita_gpt2_model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","loading configuration file ./bhagavadgita_gpt2_model/generation_config.json\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 50256,\n","  \"eos_token_id\": 50256\n","}\n","\n","loading file vocab.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/vocab.json\n","loading file merges.txt from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/merges.txt\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer_config.json\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer.json\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.44.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n","  warnings.warn(\n","The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"]},{"name":"stdout","output_type":"stream","text":["Query 1: Explain the meaning of Chapter 1, Verse 1 of the Bhagavad Gita.\n","Answer: Explain the meaning of Chapter 1, Verse 1 of the Bhagavad Gita.\n","निद्वं पुरोकृतः समेषीयसूगहैशौच न कल२४भजॉपाधऽ�\n","--------------------------------------------------\n","Query 2: What does Lord Krishna say in Chapter 2, Verse 47?\n","Answer: What does Lord Krishna say in Chapter 2, Verse 47?\n","निद्वतेषुकृरोऽपं समसीयः पूशैभगचलणजौ |\n","१हथ।बॉध९८�\n","--------------------------------------------------\n","Query 3: What is the significance of Chapter 4, Verse 7 in the Bhagavad Gita?\n","Answer: What is the significance of Chapter 4, Verse 7 in the Bhagavad Gita?\n","Bhagavan:\n","1.1 The Lord said to me, \"I am the Lord of the universe, the Supreme Being. I am not the cause of all actions.\n","I do not cause the actions of others. My actions are the result of My own actions.\"\n","2.2 The Blessed Lord spoke to Me, saying,\n","\"I have seen the world as it is\n","--------------------------------------------------\n","Query 4: What lesson is taught in Chapter 3, Verse 16?\n","Answer: What lesson is taught in Chapter 3, Verse 16?\n","\"I am the Lord of the worlds, the Ruler of all the hosts of creation. I am also the Creator of men.\n","I have the power to destroy the world. My power is the gift of knowledge. The gift is knowledge of God. It is not the knowledge that is necessary to know the universe. Knowledge is a gift. Know it. Do not be afraid. You will be destroyed. (I) am not afraid\n","--------------------------------------------------\n","Query 5: Describe the teachings of Chapter 10, Verse 20.\n","Answer: Describe the teachings of Chapter 10, Verse 20.\n","\n","\"I am the Lord of the universe, the Creator of all beings. I am all the gods, all creation, and all knowledge. All the knowledge is the same to me. My knowledge of everything is identical to the divine knowledge.\"\n"," (D&C 20:20)\n","...\n","I know the Self. The Self is My. It is all. There is no other Self than the self. (C\n","--------------------------------------------------\n","Query 6: What does Arjuna ask Krishna in Chapter 11, Verse 32?\n","Answer: What does Arjuna ask Krishna in Chapter 11, Verse 32?\n","\n","\"Why do you ask? because I am the Lord of the universe? why do I ask?\"\n"," (Krishna) replied.\n","...\n","No. I do not ask. (I) am not the cause of all actions. My actions are the result of my own actions and I have no control over them. Therefore, I cannot be the source of evil. Nor am I the origin of\n","--------------------------------------------------\n","Query 7: How does Krishna explain the cycle of life and death in Chapter 8, Verse 6?\n","Answer: How does Krishna explain the cycle of life and death in Chapter 8, Verse 6?\n","\n","Krishna:\n","...\n","No.\n","I am the Lord of the universe. I am not the cause of death. My cause is the Self. The Self is not a cause. It is a gift. If I have given it to you, I will give it again. (I) am a witness. You will not be able to hear me. Know that I do not\n","--------------------------------------------------\n","Query 8: Explain the concept of yoga as mentioned in Chapter 5, Verse 27.\n","Answer: Explain the concept of yoga as mentioned in Chapter 5, Verse 27.\n","\n","Yoga is the practice of performing the Yoga of the Self. It is a form of Yoga which is performed by the devotee. Yoga is practised by all the people of this world. The devotees perform the duties of their own bodies. They perform these duties by performing Yoga. This is called Yoga for the sake of peace and happiness. Yogi is also called the Yogic Yogin. He is\n","--------------------------------------------------\n","Query 9: What is the essence of the Bhagavad Gita?\n","Answer: What is the essence of the Bhagavad Gita?\n","Bhagavan: The Self is a Self-contained Being. It is not a single Being, but a whole Being which is distinct from the Self.\n","Self: It consists of all the elements. The elements are the threefold nature of Being (the Self, the Supreme Being and the Absolute).\n","The Self consists in the four elements (Brahma, Karma and Karma-Buddha). The four are\n","--------------------------------------------------\n","Query 10: How does the Bhagavad Gita define karma?\n","Answer: How does the Bhagavad Gita define karma?\n","\n","Karma is the highest goal of the Yogi. It is a goal that is attainable by the individual.\n",". The Yogis are the ones who have attained the goal. They are not the only ones. There are others who are also the leaders of this world. These are called the 'Brahmins'.\n","The Yogins are those who know the Self. Those who do not know it are termed the Pur\n","--------------------------------------------------\n","Query 11: What are the three gunas in the Bhagavad Gita?\n","Answer: What are the three gunas in the Bhagavad Gita?\n","Bhagavan:\n","1. The Gunas (Arjuna)\n","2. the Guna (Buddhism) and the Yoga (Yoga) are three distinct forms of Yoga.\n","3. Yoga is the practice of the Self. It is a form of meditation. Its goal is to attain the highest perfection. This is called the goal of Brahman. Brahma is Brahmic.\n","--------------------------------------------------\n","Query 12: What is Lord Krishna's advice to Arjuna regarding action and inaction?\n","Answer: What is Lord Krishna's advice to Arjuna regarding action and inaction?\n","\n","Arjina:\n",".\n"," (1) He who is not in the path of action, who has no desire to do anything, and who does not know the nature of the Self, is the one who should be called the Lord of actions. (2)\n","No one should ever be in a state of inaction. He should not be affected by the actions of others. The Lord should always be with\n","--------------------------------------------------\n","Query 13: What does the Gita say about the nature of the soul?\n","Answer: What does the Gita say about the nature of the soul?\n","\n","The Gata says that the Self is the source of all the actions.\n"," (1.1)\n","\"The Self, the Supreme Being, is everywhere. It is in all actions, everywhere, and everywhere.\"\n","No one can know the origin of action. The Self cannot be known. He is not known by the senses. His origin is unknown. There is no knowledge of him. All actions are the result\n","--------------------------------------------------\n","Query 14: How can one attain peace according to the teachings of the Bhagavad Gita?\n","Answer: How can one attain peace according to the teachings of the Bhagavad Gita?\n","\n","1.1 The Lord said, \"I am the Lord of all beings. I am all the beings of knowledge.\n","\"I know all things. My knowledge is the knowledge of everything. The knowledge I have of Myself is My own. It is all I know. All knowledge consists in Me. Me is knowledge.\"\n","I have knowledge that is known to all. That which is unknown\n","--------------------------------------------------\n","Query 15: What is the importance of devotion in the Bhagavad Gita?\n","Answer: What is the importance of devotion in the Bhagavad Gita?\n","\n","Bhagavan: The importance is in this verse.\n","Transliteration: bhavadhānāṃ vārthaṇaṅgaṣṭhānaṁca.\n","bhagavaṥ śābhāvācaṧaḥ pāpāḍyate ||11-4||\n","Translation: 11\n","--------------------------------------------------\n"]}],"source":["from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","import torch\n","\n","def evaluate_model():\n","    # Define some default queries based on the Bhagavad Gita\n","    queries = [\n","    \"Explain the meaning of Chapter 1, Verse 1 of the Bhagavad Gita.\",\n","    \"What does Lord Krishna say in Chapter 2, Verse 47?\",\n","    \"What is the significance of Chapter 4, Verse 7 in the Bhagavad Gita?\",\n","    \"What lesson is taught in Chapter 3, Verse 16?\",\n","    \"Describe the teachings of Chapter 10, Verse 20.\",\n","    \"What does Arjuna ask Krishna in Chapter 11, Verse 32?\",\n","    \"How does Krishna explain the cycle of life and death in Chapter 8, Verse 6?\",\n","    \"Explain the concept of yoga as mentioned in Chapter 5, Verse 27.\",\n","    \"What is the essence of the Bhagavad Gita?\",\n","    \"How does the Bhagavad Gita define karma?\",\n","    \"What are the three gunas in the Bhagavad Gita?\",\n","    \"What is Lord Krishna's advice to Arjuna regarding action and inaction?\",\n","    \"What does the Gita say about the nature of the soul?\",\n","    \"How can one attain peace according to the teachings of the Bhagavad Gita?\",\n","    \"What is the importance of devotion in the Bhagavad Gita?\"\n","    ]\n","\n","    # Load the fine-tuned model and tokenizer\n","    print(\"Loading the fine-tuned model...\")\n","    model = GPT2LMHeadModel.from_pretrained(\"./bhagavadgita_gpt2_model\")\n","    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","    \n","    # Set the pad token\n","    tokenizer.pad_token = tokenizer.eos_token\n","\n","    # Ensure the model is on the GPU if available\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    # Set the model to evaluation mode\n","    model.eval()\n","\n","    # Iterate through each query and get the model's generated answer\n","    for idx, question in enumerate(queries):\n","        print(f\"Query {idx+1}: {question}\")\n","        \n","        # Tokenize the input question\n","        inputs = tokenizer.encode(question, return_tensors=\"pt\").to(device)\n","\n","        # Generate the answer using the model\n","        outputs = model.generate(\n","            inputs,\n","            max_length=100,  # Maximum length of the generated answer\n","            num_return_sequences=1,  # Number of answers to generate\n","            no_repeat_ngram_size=2,  # Avoid repetition\n","            top_p=0.95,  # Top-p sampling\n","            temperature=0.1,  # Adjust the creativity of the generated text\n","            pad_token_id=tokenizer.eos_token_id\n","        )\n","\n","        # Decode the generated text\n","        answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","        # Print the answer\n","        print(f\"Answer: {answer}\")\n","        print(\"-\" * 50)\n","\n","if __name__ == \"__main__\":\n","    evaluate_model()\n"]},{"cell_type":"markdown","id":"43c822e4","metadata":{"papermill":{"duration":0.023957,"end_time":"2024-09-13T09:47:30.040812","exception":false,"start_time":"2024-09-13T09:47:30.016855","status":"completed"},"tags":[]},"source":["## END "]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":2754737,"sourceId":4759589,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":715.671389,"end_time":"2024-09-13T09:47:33.833339","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-09-13T09:35:38.16195","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"05f49d35d3ca4666a6119e3ae96e3eed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4575878116194d7a9a404fa5779381be","max":456318.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_19ce348527a4474d8479b0ca3c6b40d8","value":456318.0}},"06c5012bef0949258d8e55527596ee53":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08ed6af7061f4babbc6369f335bc4304":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e4881b9a343422987ba642022ae2724","max":1042301.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_a8899774c95c4573a77ad55a735b25b1","value":1042301.0}},"0939ee47a64d432699bd8afb67d54bbf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_11d255d5535f40b69d32893f2e1265db","IPY_MODEL_08ed6af7061f4babbc6369f335bc4304","IPY_MODEL_cdaec6aa95194e78a85ebce453c8acd6"],"layout":"IPY_MODEL_78d1d2ae2a5f43f0ab84af2dc3e469df"}},"09c18c94cd3e4c258a2e24c5118fb16f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d0351c58a2640d48c4cfae47b0d3f93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_875e0be329ca461baa46b74abed6a2fc","IPY_MODEL_05f49d35d3ca4666a6119e3ae96e3eed","IPY_MODEL_ba60a4c64bfc4f1c8f94ce89c1072ae4"],"layout":"IPY_MODEL_75b65eef6c644b2398b4bddfc764b3c7"}},"103ec98ad08349fda851ad617bba57a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11d255d5535f40b69d32893f2e1265db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bef310bf26a543acba97709fe78c651e","placeholder":"​","style":"IPY_MODEL_174fe07861d941ecbe0c41b89c6194fc","value":"vocab.json: 100%"}},"1502a0a81f5b4745a68442fb86e141c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"160659f307464468b5fc165bcc62180e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc67a228ac354f4c8bc7098c12bedac4","placeholder":"​","style":"IPY_MODEL_ac869f8f7e0f4fa0902eaa4b23dcfa8c","value":" 26.0/26.0 [00:00&lt;00:00, 1.97kB/s]"}},"161f33c8897a4f9b850d9584d3949973":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_17e4c2016c304ae691b27041eedbe58e","max":124.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_e3633bd246bd47f5956588662447af0d","value":124.0}},"174fe07861d941ecbe0c41b89c6194fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17e4c2016c304ae691b27041eedbe58e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19ce348527a4474d8479b0ca3c6b40d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1d3918b658f04b389c810b920d98f130":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5271785815cd4c8683b3cefc7acc12af","placeholder":"​","style":"IPY_MODEL_b99bd89a3c61447394ac7e4137a29019","value":"model.safetensors: 100%"}},"21e3519e388a4825b1dad7b891d2f913":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"24702ec9ffc245d0b55548861ef30afc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"252553a3977443ac8b274d246500e96c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"256641f9feb24e4b8e34c67302c852e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a8395df78734a3685a503662a304525":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2cf3172eec214cbfb49e7c2803d6bcbc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"33229c55e1994831baca6f070fd8e7d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35e0e4f625d14a0db2cbbc603a78fb07":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"365d928e71684ec7bedb912c07be58e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c4e050f2be541ea8d4c79617ec612ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d3ed0e717174a6aa23de9e8b7f7fddb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bf1ea620040c4f7295455bc522b58f0e","IPY_MODEL_90f33865d75d409ba541b6bb54c85f03","IPY_MODEL_67ba712374314789a29bc147283aae73"],"layout":"IPY_MODEL_09c18c94cd3e4c258a2e24c5118fb16f"}},"4522877450cb4980a86307adf401e875":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc422446ebf646319be0be7b37e9e689","max":701.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_252553a3977443ac8b274d246500e96c","value":701.0}},"4575878116194d7a9a404fa5779381be":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45b42dbd420741f88d35ce5041d45c6d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8577b948982c480f89c6a4d453a2ff5a","IPY_MODEL_161f33c8897a4f9b850d9584d3949973","IPY_MODEL_7d0fe6491faa424da2c3fdbb0a62a139"],"layout":"IPY_MODEL_88efd01a25ab47aa9b839a55d6dba2af"}},"45dda19c425544e6b8acd19e4cf22f21":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48319380bb864270a313b5bf04bab89d","placeholder":"​","style":"IPY_MODEL_8181601c8d1d4560b6dcf9dfaed2a29a","value":"tokenizer_config.json: 100%"}},"48319380bb864270a313b5bf04bab89d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"489396af45af41a9813cd92829123614":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4ed7daa0fc849d1a30ec52dec070573","placeholder":"​","style":"IPY_MODEL_691e508a23e1488bb7734836817bfbe3","value":" 665/665 [00:00&lt;00:00, 47.1kB/s]"}},"4c63f6358b6a44f2a0d314f11c299338":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35e0e4f625d14a0db2cbbc603a78fb07","placeholder":"​","style":"IPY_MODEL_33229c55e1994831baca6f070fd8e7d9","value":"config.json: 100%"}},"5271785815cd4c8683b3cefc7acc12af":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61a5d47dc6bf455485436919dd349410":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67ba712374314789a29bc147283aae73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61a5d47dc6bf455485436919dd349410","placeholder":"​","style":"IPY_MODEL_a629e50059ac458f9455136fab0d7457","value":" 1.36M/1.36M [00:00&lt;00:00, 10.1MB/s]"}},"691e508a23e1488bb7734836817bfbe3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"703fd22bd1cc4da98a0878ed5c719e3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89f1f53d670147d2aec572aa1f93de30","placeholder":"​","style":"IPY_MODEL_256641f9feb24e4b8e34c67302c852e3","value":" 701/701 [00:00&lt;00:00, 28838.28 examples/s]"}},"7560b9c0be4f4b88ad63bf905861f389":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"75b65eef6c644b2398b4bddfc764b3c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78d1d2ae2a5f43f0ab84af2dc3e469df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79478ae148024fe480a91c6399b78c8b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_103ec98ad08349fda851ad617bba57a5","max":26.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_d7dc12699dd4491b9cdbc5d078780018","value":26.0}},"79ff7694c7eb4ac4959bea1b8bdfa9b2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ad372eb4639469b9f6da41b162d7c44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae283559ca88490e861f10fa2f4efbc3","placeholder":"​","style":"IPY_MODEL_f22cfde67f2d45698b266762e499e244","value":"Map: 100%"}},"7d0fe6491faa424da2c3fdbb0a62a139":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b05ca21a68ba46949cd23353200144a5","placeholder":"​","style":"IPY_MODEL_f3c334ea60ed4b7d9f3a950610333289","value":" 124/124 [00:00&lt;00:00, 9.43kB/s]"}},"7e6b1525c0e34d4bbae0767a7baf261b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8181601c8d1d4560b6dcf9dfaed2a29a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83b53bcfd4994e118a276be0ba05d827":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae3468f15b21435fbfb02950a335d27c","placeholder":"​","style":"IPY_MODEL_2a8395df78734a3685a503662a304525","value":" 548M/548M [00:02&lt;00:00, 223MB/s]"}},"8577b948982c480f89c6a4d453a2ff5a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_365d928e71684ec7bedb912c07be58e7","placeholder":"​","style":"IPY_MODEL_a3b4b5d0c88f441483e533695083276a","value":"generation_config.json: 100%"}},"875e0be329ca461baa46b74abed6a2fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7935af3119841ec87327cd9279aae2c","placeholder":"​","style":"IPY_MODEL_898ea284bb214b389f8d4ec47a351e16","value":"merges.txt: 100%"}},"8826f2e90d90460592acd176c3f4e63e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88aa5c0a461f47df8b4ab5d3a90e947d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88efd01a25ab47aa9b839a55d6dba2af":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"898ea284bb214b389f8d4ec47a351e16":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89ca189cf2e649b697c5638e7f954000":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89f1f53d670147d2aec572aa1f93de30":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e4881b9a343422987ba642022ae2724":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90f33865d75d409ba541b6bb54c85f03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e6b1525c0e34d4bbae0767a7baf261b","max":1355256.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_995470552ce94b5b8c1582984ca77abc","value":1355256.0}},"995470552ce94b5b8c1582984ca77abc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a16e977ae2d4ed4aa84e1f93deca1ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbd9d4e19ed3427c90cff50e7c7389a5","max":701.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_24702ec9ffc245d0b55548861ef30afc","value":701.0}},"9e40f774c17145e280f7ca7dce157094":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a34740f5046448c49e85271e5bd407f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4c63f6358b6a44f2a0d314f11c299338","IPY_MODEL_f8055b7321164ef3848d608ad0535127","IPY_MODEL_489396af45af41a9813cd92829123614"],"layout":"IPY_MODEL_b1fca70cd5b847e9818c750187de8fd3"}},"a3b4b5d0c88f441483e533695083276a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a629e50059ac458f9455136fab0d7457":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8899774c95c4573a77ad55a735b25b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ac869f8f7e0f4fa0902eaa4b23dcfa8c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae283559ca88490e861f10fa2f4efbc3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae3468f15b21435fbfb02950a335d27c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b05ca21a68ba46949cd23353200144a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1fca70cd5b847e9818c750187de8fd3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4ed7daa0fc849d1a30ec52dec070573":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b99bd89a3c61447394ac7e4137a29019":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba60a4c64bfc4f1c8f94ce89c1072ae4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c4e050f2be541ea8d4c79617ec612ad","placeholder":"​","style":"IPY_MODEL_deeb33e961164749ade1e26378771d44","value":" 456k/456k [00:00&lt;00:00, 5.29MB/s]"}},"bc422446ebf646319be0be7b37e9e689":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bef310bf26a543acba97709fe78c651e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf1ea620040c4f7295455bc522b58f0e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f17e438927eb40159b685e849cc8e0a5","placeholder":"​","style":"IPY_MODEL_89ca189cf2e649b697c5638e7f954000","value":"tokenizer.json: 100%"}},"c2583ce35d2f4ddab0cecc989624dd0c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45dda19c425544e6b8acd19e4cf22f21","IPY_MODEL_79478ae148024fe480a91c6399b78c8b","IPY_MODEL_160659f307464468b5fc165bcc62180e"],"layout":"IPY_MODEL_1502a0a81f5b4745a68442fb86e141c3"}},"c900b352b2ca4417962adfc254f9692d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eda7389e21cf4b1ba21938952dbebf0e","IPY_MODEL_4522877450cb4980a86307adf401e875","IPY_MODEL_703fd22bd1cc4da98a0878ed5c719e3f"],"layout":"IPY_MODEL_88aa5c0a461f47df8b4ab5d3a90e947d"}},"cbd9d4e19ed3427c90cff50e7c7389a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccebb06c76d94f67a40e63761deb3b90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccefb71d2d754a8aa464b93535566343","max":548105171.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_7560b9c0be4f4b88ad63bf905861f389","value":548105171.0}},"ccefb71d2d754a8aa464b93535566343":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdaec6aa95194e78a85ebce453c8acd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8826f2e90d90460592acd176c3f4e63e","placeholder":"​","style":"IPY_MODEL_de7723ed76b84828b8cbff71a57614e9","value":" 1.04M/1.04M [00:00&lt;00:00, 8.10MB/s]"}},"d7935af3119841ec87327cd9279aae2c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7dc12699dd4491b9cdbc5d078780018":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc67a228ac354f4c8bc7098c12bedac4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de7723ed76b84828b8cbff71a57614e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"deeb33e961164749ade1e26378771d44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3633bd246bd47f5956588662447af0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5f7b16e85624cc5ba87ba6362df359a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eda7389e21cf4b1ba21938952dbebf0e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79ff7694c7eb4ac4959bea1b8bdfa9b2","placeholder":"​","style":"IPY_MODEL_2cf3172eec214cbfb49e7c2803d6bcbc","value":"Saving the dataset (1/1 shards): 100%"}},"ee6d4ee7ea5d4618b5b331e653efd420":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e40f774c17145e280f7ca7dce157094","placeholder":"​","style":"IPY_MODEL_e5f7b16e85624cc5ba87ba6362df359a","value":" 701/701 [00:04&lt;00:00, 162.36 examples/s]"}},"ef90ab0aa5bd433398edc4ac5407fa5d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1d3918b658f04b389c810b920d98f130","IPY_MODEL_ccebb06c76d94f67a40e63761deb3b90","IPY_MODEL_83b53bcfd4994e118a276be0ba05d827"],"layout":"IPY_MODEL_06c5012bef0949258d8e55527596ee53"}},"ef9e9c351e494903bd36a250539dc66d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f17e438927eb40159b685e849cc8e0a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1bb5a7a7367461fb8aaa603b8834147":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f22cfde67f2d45698b266762e499e244":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3c334ea60ed4b7d9f3a950610333289":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f48e17139abc46839e5b2e095133275e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7ad372eb4639469b9f6da41b162d7c44","IPY_MODEL_9a16e977ae2d4ed4aa84e1f93deca1ca","IPY_MODEL_ee6d4ee7ea5d4618b5b331e653efd420"],"layout":"IPY_MODEL_ef9e9c351e494903bd36a250539dc66d"}},"f8055b7321164ef3848d608ad0535127":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1bb5a7a7367461fb8aaa603b8834147","max":665.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_21e3519e388a4825b1dad7b891d2f913","value":665.0}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":5}